{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.utils import shuffle\n",
    "import importlib\n",
    "import detect_bursts\n",
    "importlib.reload(detect_bursts)\n",
    "import copy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score,f1_score,balanced_accuracy_score,confusion_matrix,ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split,cross_val_predict,StratifiedGroupKFold,StratifiedKFold\n",
    "from collections import defaultdict\n",
    "from scipy.io import loadmat\n",
    "import json\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Unlabeled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########current number of rows: 12########\n",
      "########current number of rows: 7########\n",
      "########current number of rows: 14########\n",
      "########current number of rows: 15########\n",
      "########current number of rows: 16########\n",
      "########current number of rows: 15########\n",
      "########current number of rows: 14########\n",
      "############all data loaded############\n",
      "############totalDf row number93############\n"
     ]
    }
   ],
   "source": [
    "def convertIntoFloatList(str):\n",
    "    #preprocess data extracted\n",
    "    #remove the \"[\" and \"]\" characters\n",
    "    str = str[1:-1]\n",
    "    if str == '':\n",
    "        return None\n",
    "    return np.array(str.split(','),dtype = float)\n",
    "\n",
    "def readData(frame,mothName):\n",
    "    #convert dataframe rows into an entire list\n",
    "    tp = []\n",
    "    nameArr = []\n",
    "    for ind in frame.index:\n",
    "        inc = convertIntoFloatList(frame[ind])\n",
    "        if inc is not None:\n",
    "            tp.append(inc)\n",
    "            nameArr.append(mothName)\n",
    "    return tp,nameArr\n",
    "\n",
    "#load xlsx data, extract column with largest pre_stim\n",
    "def argMaxPreStim(mothNum):\n",
    "\n",
    "    #load data from csv file\n",
    "    loadPath =  f'~/Documents/GitHub/AL_generative/timestamps_{mothNum}.csv'\n",
    "\n",
    "    df = pd.read_csv(loadPath,header=0)\n",
    "\n",
    "    argMaxColName = df.columns[np.argmax(df.iloc[0][2:]) + 2]\n",
    "    print(f\"##########current stimuli referenced: {argMaxColName}##########\")\n",
    "    return argMaxColName\n",
    "\n",
    "#load xlsx data, extract column with smallest pre_stim\n",
    "def argMinPreStim(mothNum):\n",
    "\n",
    "    #load data from csv file\n",
    "    loadPath =  f'~/Documents/GitHub/AL_generative/ALdata/timestamps_{mothNum}.csv'\n",
    "\n",
    "    df = pd.read_csv(loadPath,header=0)\n",
    "\n",
    "    argMinColName = df.columns[np.argmin(df.iloc[0][2:]) + 2]\n",
    "    print(f\"##########current stimuli referenced: {argMinColName}##########\")\n",
    "    return argMinColName\n",
    "\n",
    "#load csv data, extract timestamps\n",
    "def loadData(mothNum):\n",
    "    #load data from csv file\n",
    "    loadPath =  f'~/Documents/GitHub/AL_generative/ALdata/{mothNum}_spontaneous.csv'\n",
    "\n",
    "    df = pd.read_csv(loadPath, header = 0)\n",
    "\n",
    "    tempDf = []\n",
    "    tempName = []\n",
    "    tempNeuron = []\n",
    "    tempStimuli = []\n",
    "\n",
    "    neuronCols = list(df.columns[3:])\n",
    "    stimuli = df['stimuli'][0]\n",
    "    \n",
    "    for neuron in neuronCols:\n",
    "        curArr,nameArr = readData(df[neuron],mothNum)\n",
    "        tempDf += curArr\n",
    "        tempName += nameArr\n",
    "        tempNeuron += [neuron] * len(curArr)\n",
    "        tempStimuli += [stimuli] * len(curArr)\n",
    "\n",
    "    return tempDf,tempName,tempNeuron,tempStimuli\n",
    "\n",
    "\n",
    "#start collecting data for logistic regression\n",
    "def collectModelData(mothNames):\n",
    "    #for each moth, for each trial, for each neuron, render 9 parameters\n",
    "    totalDf = []\n",
    "    totalName = []\n",
    "    totalNeuron = []\n",
    "    totalStimuli = []\n",
    "    for mothName in mothNames:\n",
    "        mothDf,mothNameArr,mothNeuronArr,mothStimuliArr = loadData(mothName)\n",
    "        print(f\"########current number of rows: {len(mothDf)}########\")\n",
    "        totalDf += mothDf\n",
    "        totalName += mothNameArr\n",
    "        totalNeuron += mothNeuronArr\n",
    "        totalStimuli += mothStimuliArr\n",
    "    \n",
    "    print(\"############all data loaded############\")\n",
    "    #print row number of totalDf\n",
    "    print(f\"############totalDf row number{len(totalDf)}############\")\n",
    "\n",
    "    return totalDf,totalName,totalNeuron,totalStimuli\n",
    "\n",
    "#GIT data for unsupervised learning\n",
    "mothNames = ['070906', '070913', '070921', '070922', '070924_1', '070924_2', '071002']\n",
    "totalDf,totalName,totalNeuron,totalStimuli = collectModelData(mothNames)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labeled Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derive Nine Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from timestamp data count average spike frequency (spike count/duration)\n",
    "def countSpikingFreq(timestamps):\n",
    "    sum_duration = 0\n",
    "    spike_count = 0\n",
    "    for timestamp in timestamps:\n",
    "        sum_duration += timestamp[-1] - timestamp[0]\n",
    "        spike_count += len(timestamp)\n",
    "    return spike_count/sum_duration\n",
    "\n",
    "#within-burst number of spikes\n",
    "def withinBurstNumSpikes(burstIndicator):\n",
    "    num = len(np.where(burstIndicator == 1)[0])\n",
    "    percentage = num/burstIndicator.shape[0]\n",
    "    return num,percentage\n",
    "\n",
    "#burst duration and inter-burst interval\n",
    "def durations(timestamps,finalBurstRanges):\n",
    "    burst = timestamps[finalBurstRanges[0][1]] - timestamps[finalBurstRanges[0][0]]\n",
    "    #here we assume interBurst doesn't include the start-first-burst interval or the last-burst-end interval\n",
    "    interBurstSt = finalBurstRanges[0][1]\n",
    "    interBurst = 0\n",
    "\n",
    "    maxSpikingFreq = (finalBurstRanges[0][1] - finalBurstRanges[0][0] + 1)/burst\n",
    "\n",
    "    #tuple representing current burst\n",
    "    for tup in finalBurstRanges[1:]:\n",
    "        burstInc = timestamps[tup[1]] - timestamps[tup[0]]\n",
    "        burst += burstInc\n",
    "        interBurst += timestamps[tup[0]] - timestamps[interBurstSt]\n",
    "        interBurstSt = tup[1]\n",
    "\n",
    "        #count spikes within current burst\n",
    "        curSpikingFreq = (tup[1]-tup[0]+1)/burstInc\n",
    "        if maxSpikingFreq < curSpikingFreq:\n",
    "            maxSpikingFreq = curSpikingFreq\n",
    "\n",
    "    # burst /= 1000\n",
    "    # interBurst /= 1000\n",
    "    # maxSpikingFreq *= 1000\n",
    "    return burst,interBurst,maxSpikingFreq\n",
    "\n",
    "#within-burst spiking frequency\n",
    "def meanSpikingFreq(num,duration):\n",
    "    return num/duration\n",
    "    # return num/duration * 1000\n",
    "\n",
    "#surprise values\n",
    "def surpriseEval(finalBurstSurprises):\n",
    "    meanSurprise = np.mean(finalBurstSurprises)\n",
    "    maxSurprise = np.max(finalBurstSurprises)\n",
    "    return meanSurprise,maxSurprise\n",
    "\n",
    "#mean burst frequency\n",
    "def meanBurstFreq(finalNumBursts,totalTime):\n",
    "    meanburstFreq = finalNumBursts/totalTime\n",
    "    # meanburstFreq = meanburstFreq* 1000\n",
    "    return meanburstFreq\n",
    "\n",
    "#render 9 parameters for each sample (1 trial of 1 neuron)\n",
    "def renderParams(timestamps,finalBurstRanges,finalBurstSurprises,burstIndicator,finalNumBursts,totalTime):\n",
    "    withinBurstSpikeNum,withinBurstSpikePercentage = withinBurstNumSpikes(burstIndicator)\n",
    "    duration,interBurst,maxSpikingFreq = durations(timestamps,finalBurstRanges)\n",
    "    meanSpikingFreq = withinBurstSpikeNum/duration\n",
    "    meanSurprise,maxSurprise = surpriseEval(finalBurstSurprises)\n",
    "    meanburstFreq = meanBurstFreq(finalNumBursts,totalTime)\n",
    "    return [duration,meanSpikingFreq,maxSpikingFreq,withinBurstSpikeNum,\\\n",
    "            interBurst,withinBurstSpikePercentage,meanburstFreq,meanSurprise,maxSurprise]\n",
    "\n",
    "\n",
    "def formulateDataset(totalDf,totalName = None,totalLabel = None,p = 0.5):\n",
    "    sampleDataset = []\n",
    "    nameRes = []\n",
    "    labelRes = []\n",
    "\n",
    "    no_burst_sampleDataset = []\n",
    "    no_burst_nameRes = []\n",
    "    no_burst_labelRes = []\n",
    "\n",
    "    if totalName is None:\n",
    "        totalName = ['']*(totalDf.shape[0])\n",
    "\n",
    "    if totalLabel is None:\n",
    "        totalLabel = [0]*(totalDf.shape[0])\n",
    "        \n",
    "    for index,dfRow in enumerate(totalDf):\n",
    "        lInput = [0] + dfRow\n",
    "        burstIndicator,finalNumBursts,finalBurstRanges,finalBurstSurprises,totalTime = detect_bursts.detectBursts(lInput,0,math.inf,2,p)\n",
    "        \n",
    "        if finalBurstRanges != []:\n",
    "            sampleDataset.append(renderParams(\\\n",
    "                lInput,finalBurstRanges,finalBurstSurprises,\\\n",
    "                    burstIndicator,finalNumBursts,totalTime))\n",
    "            nameRes.append(totalName[index])\n",
    "            labelRes.append(totalLabel[index])\n",
    "\n",
    "        else:\n",
    "            #no burst in current list of timestamps\n",
    "            no_burst_sampleDataset.append(dfRow)\n",
    "            no_burst_nameRes.append(totalName[index])\n",
    "            no_burst_labelRes.append(totalLabel[index])\n",
    "\n",
    "    return sampleDataset,nameRes,labelRes,\\\n",
    "        no_burst_sampleDataset,no_burst_nameRes,no_burst_labelRes\n",
    "\n",
    "\n",
    "\n",
    "def formulateDataset_unlabeled(totalDf,totalName = None,totalNeuron = None,totalStimuli = None,p = 0.5):\n",
    "    sampleDataset = []\n",
    "    nameRes = []\n",
    "    neuronRes = []\n",
    "    stimuliRes = []\n",
    "\n",
    "    no_burst_sampleDataset = []\n",
    "    no_burst_nameRes = []\n",
    "    no_burst_neuronRes = []\n",
    "    no_burst_stimuliRes = []\n",
    "\n",
    "\n",
    "    if totalName is None:\n",
    "        totalName = ['']*(len(totalDf))\n",
    "\n",
    "    \n",
    "    if totalNeuron is None:\n",
    "        totalNeuron = ['']*(len(totalDf))\n",
    "    \n",
    "    if totalStimuli is None:\n",
    "        totalStimuli = ['']*(len(totalDf))\n",
    "        \n",
    "    for index,dfRow in enumerate(totalDf):\n",
    "        lInput = [0] + dfRow\n",
    "        burstIndicator,finalNumBursts,finalBurstRanges,finalBurstSurprises,totalTime = detect_bursts.detectBursts(lInput,0,math.inf,2,p)\n",
    "        \n",
    "        if finalBurstRanges != []:\n",
    "            sampleDataset.append(renderParams(\\\n",
    "                lInput,finalBurstRanges,finalBurstSurprises,\\\n",
    "                    burstIndicator,finalNumBursts,totalTime))\n",
    "            nameRes.append(totalName[index])\n",
    "            neuronRes.append(totalNeuron[index])\n",
    "            stimuliRes.append(totalStimuli[index])\n",
    "\n",
    "        else:\n",
    "            #no burst in current list of timestamps\n",
    "            no_burst_sampleDataset.append(dfRow)\n",
    "            no_burst_nameRes.append(totalName[index])\n",
    "            no_burst_neuronRes.append(totalNeuron[index])\n",
    "            no_burst_stimuliRes.append(totalStimuli[index])\n",
    "\n",
    "    return sampleDataset,nameRes,neuronRes,stimuliRes,\\\n",
    "        no_burst_sampleDataset,no_burst_nameRes,no_burst_neuronRes,no_burst_stimuliRes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#unsupervised -- save data into csv file\n",
    "def saveData(Dataset,nameRes,neuronRes,stimuliRes):\n",
    "    #load data from csv file\n",
    "    savePath =  'unsupervised_learning/nine_parameters.csv'\n",
    "\n",
    "    df = pd.DataFrame(Dataset,columns=\\\n",
    "                      ['burst duration','within-burst spiking freq','within-burst max spiking freq',\\\n",
    "                       'within-burst number of spikes',\\\n",
    "                       'inter-burst interval','percentage of burst spikes','burst frequency',\\\n",
    "                        'mean surprise','max surprise'])\n",
    "    \n",
    "    #also include subject and stimuli name\n",
    "    df['Subject'] = nameRes\n",
    "    df['Neuron'] = neuronRes\n",
    "    df['Stimuli'] = stimuliRes\n",
    "    \n",
    "    # df.to_csv(savePath, index=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "#supervised -- save data into csv file\n",
    "def supervised_saveData(dataset,nameRes,labelRes,save_path = \"~/Documents/GitHub/AL_generative/labeled_data/nine_burst_parameters.csv\"):\n",
    "    df = pd.DataFrame(dataset,columns=\\\n",
    "                      ['burst duration','within-burst spiking freq','within-burst max spiking freq',\\\n",
    "                       'within-burst number of spikes',\\\n",
    "                       'inter-burst interval','percentage of burst spikes','burst frequency',\\\n",
    "                        'mean surprise','max surprise'])\n",
    "    \n",
    "    #also include subject and stimuli name\n",
    "    df['Subject'] = nameRes\n",
    "    df['label'] = labelRes\n",
    "    \n",
    "    # #save parameters into csv file\n",
    "    # df.to_csv(save_path, index=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def histoResults(DF,lstColumnNames,plotFunc,plotParams,saveFileName = 'compare_histograms.pdf',barplot = False,\\\n",
    "                 figsize = (100,50),main_title = 'Comparison of histograms of 9 parameters',alpha = 0.3):\n",
    "    #3x3 subplots\n",
    "    fig,ax = plt.subplots(3,3,figsize=(15,15))\n",
    "    # fig = plt.figure(figsize=figsize)\n",
    "    #sns plot with hue of each of the nine parameters on a row for datapoints in each cluster\n",
    "    num = len(lstColumnNames)\n",
    "    for j in range(num):\n",
    "        #use \"y = \" for barplot, \"x =  \" otherwise\n",
    "        #figure into the jth subplot\n",
    "        # fig.add_subplot(num,1,j+1)\n",
    "        \n",
    "        if barplot:\n",
    "            #call barplot function, add a subplot to the 3x3 grid\n",
    "            plotFunc(data=DF,y=lstColumnNames[j],ax=ax[j//3,j%3],**plotParams)\n",
    "\n",
    "            \n",
    "            for bar in ax[j//3,j%3].containers[0]:\n",
    "                bar.set_alpha(alpha)\n",
    "\n",
    "        else:\n",
    "            #call plot function, add a subplot to the 3x3 grid\n",
    "            plotFunc(data=DF,x=lstColumnNames[j],ax=ax[j//3,j%3],**plotParams)\n",
    "\n",
    "\n",
    "        \n",
    "            \n",
    "    #main title\n",
    "    fig.suptitle(main_title)\n",
    "\n",
    "    #save pdf\n",
    "    fig.savefig(saveFileName)\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "\n",
    "ts = pd.read_pickle(\"LNandPN.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose appropriate p values and parameters for each of the three datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-10 15:21:09,104] A new study created in memory with name: no-name-58661574-ca6b-4723-9ebf-3936279441be\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######Start Burst Detection, trial: 0#######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-10 15:21:45,434] Trial 0 finished with value: 0.6236559139784946 and parameters: {'solver': 'lbfgs', 'C': 6.2852581441108e-05, 'tol': 0.008757048513661218, 'scaler': 'minmax', 'prune': 'no', 'p_labeled': 0.344129236465516, 'p_unlabeled': 0.3442606321274472}. Best is trial 0 with value: 0.6236559139784946.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######Burst Detection Finished, trial: 0#######\n",
      "#######Start Logistic Regression, trial: 0#######\n",
      "#######Logistic Regression Finished, trial: 0#######\n",
      "#######Start Prediction on Unlabeled Test Set and Compute Accuracy, trial: 0#######\n",
      "#######Output Accuracy: 0.6236559139784946, trial: 0#######\n",
      "#######Start Burst Detection, trial: 1#######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-10 15:22:30,253] Trial 1 finished with value: 0.6881720430107527 and parameters: {'solver': 'newton-cg', 'C': 5.967507942713243, 'tol': 8.979168543780659e-05, 'scaler': 'standard', 'prune': 'yes', 'p_labeled': 0.6049148359349295, 'p_unlabeled': 0.569156256572099}. Best is trial 1 with value: 0.6881720430107527.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######Burst Detection Finished, trial: 1#######\n",
      "#######Start Logistic Regression, trial: 1#######\n",
      "#######Logistic Regression Finished, trial: 1#######\n",
      "#######Start Prediction on Unlabeled Test Set and Compute Accuracy, trial: 1#######\n",
      "#######Output Accuracy: 0.6881720430107527, trial: 1#######\n",
      "#######Start Burst Detection, trial: 2#######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-10 15:23:12,599] Trial 2 finished with value: 0.5483870967741935 and parameters: {'solver': 'sag', 'C': 126.65113459530203, 'tol': 0.031836142691665875, 'scaler': 'minmax', 'prune': 'yes', 'p_labeled': 0.5022316699324237, 'p_unlabeled': 0.5514122617165245}. Best is trial 1 with value: 0.6881720430107527.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######Burst Detection Finished, trial: 2#######\n",
      "#######Start Logistic Regression, trial: 2#######\n",
      "#######Logistic Regression Finished, trial: 2#######\n",
      "#######Start Prediction on Unlabeled Test Set and Compute Accuracy, trial: 2#######\n",
      "#######Output Accuracy: 0.5483870967741935, trial: 2#######\n",
      "#######Start Burst Detection, trial: 3#######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-10 15:23:46,104] Trial 3 finished with value: 0.6344086021505376 and parameters: {'solver': 'liblinear', 'C': 5.988043454713249e-05, 'tol': 5.258424088180168e-05, 'scaler': 'minmax', 'prune': 'yes', 'p_labeled': 0.749021255658305, 'p_unlabeled': 0.15429392053795432}. Best is trial 1 with value: 0.6881720430107527.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######Burst Detection Finished, trial: 3#######\n",
      "#######Start Logistic Regression, trial: 3#######\n",
      "#######Logistic Regression Finished, trial: 3#######\n",
      "#######Start Prediction on Unlabeled Test Set and Compute Accuracy, trial: 3#######\n",
      "#######Output Accuracy: 0.6344086021505376, trial: 3#######\n",
      "#######Start Burst Detection, trial: 4#######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-10 15:24:25,608] Trial 4 finished with value: 0.6344086021505376 and parameters: {'solver': 'liblinear', 'C': 0.5466408900984469, 'tol': 0.04252838421809207, 'scaler': 'minmax', 'prune': 'yes', 'p_labeled': 0.7244517419238207, 'p_unlabeled': 0.2738079327468748}. Best is trial 1 with value: 0.6881720430107527.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######Burst Detection Finished, trial: 4#######\n",
      "#######Start Logistic Regression, trial: 4#######\n",
      "#######Logistic Regression Finished, trial: 4#######\n",
      "#######Start Prediction on Unlabeled Test Set and Compute Accuracy, trial: 4#######\n",
      "#######Output Accuracy: 0.6344086021505376, trial: 4#######\n",
      "#######Start Burst Detection, trial: 5#######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-10 15:25:12,526] Trial 5 finished with value: 0.5268817204301075 and parameters: {'solver': 'newton-cg', 'C': 136.62140021066196, 'tol': 0.00041747937774072304, 'scaler': 'minmax', 'prune': 'yes', 'p_labeled': 0.6426952991934234, 'p_unlabeled': 0.8815228561600941}. Best is trial 1 with value: 0.6881720430107527.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######Burst Detection Finished, trial: 5#######\n",
      "#######Start Logistic Regression, trial: 5#######\n",
      "#######Logistic Regression Finished, trial: 5#######\n",
      "#######Start Prediction on Unlabeled Test Set and Compute Accuracy, trial: 5#######\n",
      "#######Output Accuracy: 0.5268817204301075, trial: 5#######\n",
      "#######Start Burst Detection, trial: 6#######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-03-10 15:25:38,766] Trial 6 failed with parameters: {'solver': 'sag', 'C': 5.2833403043456933e-05, 'tol': 0.0023656533943206804, 'scaler': 'standard', 'prune': 'no', 'p_labeled': 0.297951543645423, 'p_unlabeled': 0.46927404427344666} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/var/folders/q1/h8sfffrj2ns04crg9tlwvvjh0000gn/T/ipykernel_10134/2270897831.py\", line 54, in lr_objective\n",
      "    = formulateDataset_unlabeled(totalDf,totalName,totalNeuron,totalStimuli,p = p_unlabeled)\n",
      "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/q1/h8sfffrj2ns04crg9tlwvvjh0000gn/T/ipykernel_10134/2941733778.py\", line 131, in formulateDataset_unlabeled\n",
      "    burstIndicator,finalNumBursts,finalBurstRanges,finalBurstSurprises,totalTime = detect_bursts.detectBursts(lInput,0,math.inf,2,p)\n",
      "                                                                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ocelottamer/Documents/GitHub/AL_generative/poissonSurprise/detect_bursts.py\", line 176, in detectBursts\n",
      "    cropBurstRanges,cropBurstSurprises,cropNumBursts = cropBursts(burstRanges,burstSurprises,intervals,meanFreq)\n",
      "                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ocelottamer/Documents/GitHub/AL_generative/poissonSurprise/detect_bursts.py\", line 132, in cropBursts\n",
      "    surprise = poissonSurprise(number,meanFreq,period)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ocelottamer/Documents/GitHub/AL_generative/poissonSurprise/detect_bursts.py\", line 38, in poissonSurprise\n",
      "    nsum(lambda i:(meanFiringRate*interval)**i/fac(i),\\\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/mpmath/calculus/extrapolation.py\", line 1718, in nsum\n",
      "    return +ctx.adaptive_extrapolation(update, emfun, options)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/mpmath/calculus/extrapolation.py\", line 1196, in adaptive_extrapolation\n",
      "    shanks_table = ctx.shanks(partial, shanks_table, randomized=True)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/mpmath/calculus/extrapolation.py\", line 247, in shanks\n",
      "    a, b = 0, seq[i+1]-seq[i]\n",
      "              ~~~~~~~~^~~~~~~\n",
      "  File \"<string>\", line 7, in __sub__\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/mpmath/libmp/libmpf.py\", line 800, in mpf_sub\n",
      "    return mpf_add(s, t, prec, rnd, 1)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/mpmath/libmp/libmpf.py\", line 765, in mpf_add\n",
      "    bc = bitcount(man)\n",
      "         ^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/mpmath/libmp/libintmath.py\", line 91, in python_bitcount\n",
      "    def python_bitcount(n):\n",
      "    \n",
      "KeyboardInterrupt\n",
      "[W 2024-03-10 15:25:38,769] Trial 6 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 103\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pred_accu\n\u001b[1;32m    102\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 103\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr_objective\u001b[49m\u001b[43m,\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m display(study\u001b[38;5;241m.\u001b[39mbest_params,study\u001b[38;5;241m.\u001b[39mbest_value)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[27], line 54\u001b[0m, in \u001b[0;36mlr_objective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     48\u001b[0m ts_df_pruned \u001b[38;5;241m=\u001b[39m ts_df[pruned_nine_cols]\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m#unlabeled\u001b[39;00m\n\u001b[1;32m     51\u001b[0m unlabeled_sampleDataset,unlabeled_nameRes,unlabeled_neuronRes,unlabeled_stimuliRes,\\\n\u001b[1;32m     52\u001b[0m         unlabeled_no_burst_sampleDataset,unlabeled_no_burst_nameRes,\\\n\u001b[1;32m     53\u001b[0m             unlabeled_no_burst_neuronRes,unlabeled_no_burst_stimuliRes,\\\n\u001b[0;32m---> 54\u001b[0m             \u001b[38;5;241m=\u001b[39m \u001b[43mformulateDataset_unlabeled\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotalDf\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtotalName\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtotalNeuron\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtotalStimuli\u001b[49m\u001b[43m,\u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mp_unlabeled\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m unlabeled_df \u001b[38;5;241m=\u001b[39m saveData(unlabeled_sampleDataset,unlabeled_nameRes,unlabeled_neuronRes,unlabeled_stimuliRes)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m#no 'label' column here, so we add :-1\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 131\u001b[0m, in \u001b[0;36mformulateDataset_unlabeled\u001b[0;34m(totalDf, totalName, totalNeuron, totalStimuli, p)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index,dfRow \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(totalDf):\n\u001b[1;32m    130\u001b[0m     lInput \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m dfRow\n\u001b[0;32m--> 131\u001b[0m     burstIndicator,finalNumBursts,finalBurstRanges,finalBurstSurprises,totalTime \u001b[38;5;241m=\u001b[39m \u001b[43mdetect_bursts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetectBursts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlInput\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minf\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m finalBurstRanges \u001b[38;5;241m!=\u001b[39m []:\n\u001b[1;32m    134\u001b[0m         sampleDataset\u001b[38;5;241m.\u001b[39mappend(renderParams(\\\n\u001b[1;32m    135\u001b[0m             lInput,finalBurstRanges,finalBurstSurprises,\\\n\u001b[1;32m    136\u001b[0m                 burstIndicator,finalNumBursts,totalTime))\n",
      "File \u001b[0;32m~/Documents/GitHub/AL_generative/poissonSurprise/detect_bursts.py:176\u001b[0m, in \u001b[0;36mdetectBursts\u001b[0;34m(timeStamps, minSurprise, maxNumBurstSpikes, numISI, p)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdetectBursts\u001b[39m(timeStamps,minSurprise,maxNumBurstSpikes,numISI,p \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m):\n\u001b[1;32m    174\u001b[0m     burstRanges,burstSurprises,intervals,totalTime,meanFreq,numSpikes \u001b[38;5;241m=\u001b[39m potentialBursts(timeStamps,maxNumBurstSpikes,numISI,p)\n\u001b[0;32m--> 176\u001b[0m     cropBurstRanges,cropBurstSurprises,cropNumBursts \u001b[38;5;241m=\u001b[39m \u001b[43mcropBursts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mburstRanges\u001b[49m\u001b[43m,\u001b[49m\u001b[43mburstSurprises\u001b[49m\u001b[43m,\u001b[49m\u001b[43mintervals\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmeanFreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     burstIndicator,finalBurstRanges,finalBurstSurprises,finalNumBursts \u001b[38;5;241m=\u001b[39m          finalBursts(cropBurstRanges,cropBurstSurprises,cropNumBursts,minSurprise,numSpikes)\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m burstIndicator,finalNumBursts,finalBurstRanges,finalBurstSurprises,totalTime\n",
      "File \u001b[0;32m~/Documents/GitHub/AL_generative/poissonSurprise/detect_bursts.py:132\u001b[0m, in \u001b[0;36mcropBursts\u001b[0;34m(burstRanges, burstSurprises, intervals, meanFreq)\u001b[0m\n\u001b[1;32m    130\u001b[0m period \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(intervals[startIndex\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m:endIndex\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    131\u001b[0m number \u001b[38;5;241m=\u001b[39m endIndex \u001b[38;5;241m-\u001b[39m startIndex\n\u001b[0;32m--> 132\u001b[0m surprise \u001b[38;5;241m=\u001b[39m \u001b[43mpoissonSurprise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmeanFreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43mperiod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m surprise \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m maxSurprise:\n\u001b[1;32m    135\u001b[0m     cropStartIndex \u001b[38;5;241m=\u001b[39m startIndex\n",
      "File \u001b[0;32m~/Documents/GitHub/AL_generative/poissonSurprise/detect_bursts.py:38\u001b[0m, in \u001b[0;36mpoissonSurprise\u001b[0;34m(numISI, meanFiringRate, interval)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpoissonSurprise\u001b[39m(numISI,meanFiringRate,interval):\n\u001b[1;32m     37\u001b[0m     P \u001b[38;5;241m=\u001b[39m exp(\u001b[38;5;241m-\u001b[39mmeanFiringRate\u001b[38;5;241m*\u001b[39minterval)\u001b[38;5;241m*\u001b[39m\\\n\u001b[0;32m---> 38\u001b[0m         \u001b[43mnsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmeanFiringRate\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterval\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mfac\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m             \u001b[49m\u001b[43m[\u001b[49m\u001b[43mnumISI\u001b[49m\u001b[43m,\u001b[49m\u001b[43minf\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;66;03m#mitigate math domain error as we currently haven't found why it occasionally gives zero\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/mpmath/calculus/extrapolation.py:1718\u001b[0m, in \u001b[0;36mnsum\u001b[0;34m(ctx, f, *intervals, **options)\u001b[0m\n\u001b[1;32m   1715\u001b[0m     ctx\u001b[38;5;241m.\u001b[39mprec \u001b[38;5;241m=\u001b[39m workprec\n\u001b[1;32m   1716\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m v\n\u001b[0;32m-> 1718\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m+\u001b[39m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madaptive_extrapolation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/mpmath/calculus/extrapolation.py:1196\u001b[0m, in \u001b[0;36madaptive_extrapolation\u001b[0;34m(ctx, update, emfun, kwargs)\u001b[0m\n\u001b[1;32m   1194\u001b[0m         best \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TRY_SHANKS:\n\u001b[0;32m-> 1196\u001b[0m     shanks_table \u001b[38;5;241m=\u001b[39m \u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshanks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshanks_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1197\u001b[0m     row \u001b[38;5;241m=\u001b[39m shanks_table[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1198\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(row) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/mpmath/calculus/extrapolation.py:247\u001b[0m, in \u001b[0;36mshanks\u001b[0;34m(ctx, seq, table, randomized)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m xrange(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m j \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 247\u001b[0m         a, b \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[43mseq\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mseq\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    249\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m j \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m<string>:7\u001b[0m, in \u001b[0;36m__sub__\u001b[0;34m(self, other)\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/mpmath/libmp/libmpf.py:800\u001b[0m, in \u001b[0;36mmpf_sub\u001b[0;34m(s, t, prec, rnd)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmpf_sub\u001b[39m(s, t, prec\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, rnd\u001b[38;5;241m=\u001b[39mround_fast):\n\u001b[1;32m    798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the difference of two raw mpfs, s-t. This function is\u001b[39;00m\n\u001b[1;32m    799\u001b[0m \u001b[38;5;124;03m    simply a wrapper of mpf_add that changes the sign of t.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 800\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmpf_add\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrnd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/mpmath/libmp/libmpf.py:765\u001b[0m, in \u001b[0;36mmpf_add\u001b[0;34m(s, t, prec, rnd, _sub)\u001b[0m\n\u001b[1;32m    763\u001b[0m                 man \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mman\n\u001b[1;32m    764\u001b[0m                 ssign \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 765\u001b[0m         bc \u001b[38;5;241m=\u001b[39m \u001b[43mbitcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43mman\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    766\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m normalize1(ssign, man, sexp, bc, prec \u001b[38;5;129;01mor\u001b[39;00m bc, rnd)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;66;03m# Equal exponents; no shifting necessary\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/mpmath/libmp/libintmath.py:91\u001b[0m, in \u001b[0;36mpython_bitcount\u001b[0;34m(n)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Small powers of 2\u001b[39;00m\n\u001b[1;32m     89\u001b[0m powers \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m<<\u001b[39m_ \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m300\u001b[39m)]\n\u001b[0;32m---> 91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpython_bitcount\u001b[39m(n):\n\u001b[1;32m     92\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calculate bit size of the nonnegative integer n.\"\"\"\u001b[39;00m\n\u001b[1;32m     93\u001b[0m     bc \u001b[38;5;241m=\u001b[39m bisect(powers, n)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_label_from_true_json(data,name_base,neuron_base,true_json_data):\n",
    "    true_label = []\n",
    "\n",
    "    for i,label in enumerate(data):\n",
    "        true_label.append(true_json_data[name_base[i]][neuron_base[i]]['true'])\n",
    "\n",
    "\n",
    "    return true_label\n",
    "\n",
    "true_json_data = json.load(open('unlabeled_pred.json'))\n",
    "\n",
    "\n",
    "\n",
    "def lr_objective(trial):\n",
    "    #lr parameters\n",
    "    solver = trial.suggest_categorical('solver',['newton-cg','lbfgs','liblinear','sag','saga'])\n",
    "    C = trial.suggest_loguniform('C',1e-5,1e2)\n",
    "    tol = trial.suggest_loguniform('tol',1e-5,1e-1)\n",
    "\n",
    "    #scaler\n",
    "    scaler_label = trial.suggest_categorical('scaler',['standard','minmax'])\n",
    "    if scaler_label == 'standard':\n",
    "        scaler = preprocessing.StandardScaler()\n",
    "    else:\n",
    "        scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "    #choice of 9 columns\n",
    "    prune = trial.suggest_categorical('prune',['yes','no'])\n",
    "    if prune == 'yes':\n",
    "        pruned_nine_cols = ['within-burst max spiking freq',\\\n",
    "                    'within-burst number of spikes','percentage of burst spikes','burst frequency',\\\n",
    "                        'mean surprise','max surprise','label']\n",
    "    else:\n",
    "        pruned_nine_cols = ['within-burst number of spikes','burst frequency',\\\n",
    "                            'mean surprise','max surprise','label']\n",
    "\n",
    "    #p parameter\n",
    "    p_labeled = trial.suggest_float('p_labeled',0.1,0.9)\n",
    "    p_unlabeled = trial.suggest_float('p_unlabeled',0.1,0.9)\n",
    "\n",
    "    #exploratory data analysis\n",
    "    print(f\"#######Start Burst Detection, trial: {trial.number}#######\")\n",
    "    #ts\n",
    "    ts_sampleDataset,ts_nameRes,ts_labelRes,\\\n",
    "        ts_no_burst_sampleDataset,ts_no_burst_nameRes,\\\n",
    "            ts_no_burst_labelRes = formulateDataset(ts['timestamps'],ts['mothname'],ts['label'],p = p_labeled)\n",
    "    ts_df = supervised_saveData(ts_sampleDataset,ts_nameRes,ts_labelRes)\n",
    "    ts_df_pruned = ts_df[pruned_nine_cols]\n",
    "\n",
    "    #unlabeled\n",
    "    unlabeled_sampleDataset,unlabeled_nameRes,unlabeled_neuronRes,unlabeled_stimuliRes,\\\n",
    "            unlabeled_no_burst_sampleDataset,unlabeled_no_burst_nameRes,\\\n",
    "                unlabeled_no_burst_neuronRes,unlabeled_no_burst_stimuliRes,\\\n",
    "                = formulateDataset_unlabeled(totalDf,totalName,totalNeuron,totalStimuli,p = p_unlabeled)\n",
    "    unlabeled_df = saveData(unlabeled_sampleDataset,unlabeled_nameRes,unlabeled_neuronRes,unlabeled_stimuliRes)\n",
    "    #no 'label' column here, so we add :-1\n",
    "    unlabeled_df_pruned = unlabeled_df[pruned_nine_cols[:-1]]\n",
    "\n",
    "    #take every fold as a test set and the rest as training set, setup scaler w.r.t. training set\n",
    "    #preprocessing with scaler on ts data \n",
    "    ts_df_pruned_processed = scaler.fit_transform(ts_df_pruned.iloc[:,:-1])\n",
    "\n",
    "    print(f\"#######Burst Detection Finished, trial: {trial.number}#######\")\n",
    "\n",
    "    print(f\"#######Start Logistic Regression, trial: {trial.number}#######\")\n",
    "\n",
    "\n",
    "    lr = LogisticRegression(solver = solver,C = C,tol = tol)\n",
    "\n",
    "    #fit the model\n",
    "    #display number of columns of ts_df_pruned_processed\n",
    "    # print(f\"#######Number of columns of ts_df_pruned_processed: {ts_df_pruned_processed.shape[1]}#######\")\n",
    "    lr.fit(ts_df_pruned_processed,ts_df_pruned['label'])\n",
    "\n",
    "    #preprocessing with scaler on unlabeled data\n",
    "    unlabeled_df_pruned_processed = scaler.fit_transform(unlabeled_df_pruned)\n",
    "    #display number of columns of unlabeled_df_pruned_processed\n",
    "    # print(f\"#######Number of columns of unlabeled_df_pruned_processed: {unlabeled_df_pruned_processed.shape[1]}#######\")\n",
    "    print(f\"#######Logistic Regression Finished, trial: {trial.number}#######\")\n",
    "\n",
    "\n",
    "    #predict on test set\n",
    "    print(f\"#######Start Prediction on Unlabeled Test Set and Compute Accuracy, trial: {trial.number}#######\")\n",
    "    pred_label = lr.predict(unlabeled_df_pruned_processed)\n",
    "\n",
    "\n",
    "    true_labels = get_label_from_true_json(pred_label,unlabeled_nameRes,unlabeled_neuronRes,true_json_data)\n",
    "    true_labels_no_burst = get_label_from_true_json(unlabeled_no_burst_nameRes,unlabeled_no_burst_nameRes,unlabeled_no_burst_neuronRes,true_json_data)\n",
    "    true_labels_extended = true_labels + true_labels_no_burst\n",
    "    #replace 0 in pred_label as 'LN' and 1 as 'PN'\n",
    "    pred_label = list(map(lambda x: 'LN' if x == 0 else 'PN',pred_label))\n",
    "    #append LNs after predicted labels\n",
    "    unlabeled_pred_extended = list(pred_label + ['LN']*len(unlabeled_no_burst_nameRes))\n",
    "\n",
    "    #compute accuracy\n",
    "    pred_accu = accuracy_score(true_labels_extended,unlabeled_pred_extended)\n",
    "    print(f\"#######Output Accuracy: {pred_accu}, trial: {trial.number}#######\")\n",
    "\n",
    "    return pred_accu\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lr_objective,n_trials=100)\n",
    "\n",
    "display(study.best_params,study.best_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
